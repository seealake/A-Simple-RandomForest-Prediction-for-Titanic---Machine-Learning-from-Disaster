{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using RandomForest to Predict Survival Rate of Titanic","metadata":{}},{"cell_type":"markdown","source":"# (1): Let's start by visualizing the data from train.csv","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndf = pd.read_csv('/kaggle/input/titanic/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:39.508420Z","iopub.execute_input":"2025-01-11T12:22:39.508891Z","iopub.status.idle":"2025-01-11T12:22:39.523121Z","shell.execute_reply.started":"2025-01-11T12:22:39.508846Z","shell.execute_reply":"2025-01-11T12:22:39.521692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:39.524868Z","iopub.execute_input":"2025-01-11T12:22:39.525373Z","iopub.status.idle":"2025-01-11T12:22:39.549710Z","shell.execute_reply.started":"2025-01-11T12:22:39.525327Z","shell.execute_reply":"2025-01-11T12:22:39.548287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:39.552498Z","iopub.execute_input":"2025-01-11T12:22:39.552861Z","iopub.status.idle":"2025-01-11T12:22:39.593246Z","shell.execute_reply.started":"2025-01-11T12:22:39.552809Z","shell.execute_reply":"2025-01-11T12:22:39.592098Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check the survival rate","metadata":{}},{"cell_type":"code","source":"survived_rate = df.iloc[1:]['Survived'].mean()\nplt.bar(['Survived', 'Not survived'], [survived_rate, 1-survived_rate])\nplt.ylim(0, 1)\nplt.title('Survived vs Not Survived')\nplt.grid(True)\nplt.text(0, survived_rate, f'{survived_rate:.3f}', ha='center', va='bottom')\nplt.text(1, 1-survived_rate, f'{1-survived_rate:.3f}', ha='center', va='bottom')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:39.595206Z","iopub.execute_input":"2025-01-11T12:22:39.595703Z","iopub.status.idle":"2025-01-11T12:22:39.820306Z","shell.execute_reply.started":"2025-01-11T12:22:39.595663Z","shell.execute_reply":"2025-01-11T12:22:39.819236Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check the Pclass","metadata":{}},{"cell_type":"code","source":"df[\"Pclass\"].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:39.821448Z","iopub.execute_input":"2025-01-11T12:22:39.821901Z","iopub.status.idle":"2025-01-11T12:22:39.833089Z","shell.execute_reply.started":"2025-01-11T12:22:39.821858Z","shell.execute_reply":"2025-01-11T12:22:39.831900Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"Pclass\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:39.834523Z","iopub.execute_input":"2025-01-11T12:22:39.834988Z","iopub.status.idle":"2025-01-11T12:22:39.860311Z","shell.execute_reply.started":"2025-01-11T12:22:39.834944Z","shell.execute_reply":"2025-01-11T12:22:39.859224Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We then check the survival rates of different categories of Pclass","metadata":{}},{"cell_type":"code","source":"df.groupby(\"Pclass\")[\"Survived\"].mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:39.861365Z","iopub.execute_input":"2025-01-11T12:22:39.861644Z","iopub.status.idle":"2025-01-11T12:22:39.884350Z","shell.execute_reply.started":"2025-01-11T12:22:39.861612Z","shell.execute_reply":"2025-01-11T12:22:39.883060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check the mean survival rates of different bins of Age","metadata":{}},{"cell_type":"code","source":"survival_age = df.groupby(pd.cut(df['Age'], bins=range(0, 100, 5)), observed=True)['Survived'].mean()\nsurvival_age","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:39.885458Z","iopub.execute_input":"2025-01-11T12:22:39.886244Z","iopub.status.idle":"2025-01-11T12:22:39.915598Z","shell.execute_reply.started":"2025-01-11T12:22:39.886198Z","shell.execute_reply":"2025-01-11T12:22:39.914123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.bar(survival_age.index.astype(str), survival_age)\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:39.919015Z","iopub.execute_input":"2025-01-11T12:22:39.919331Z","iopub.status.idle":"2025-01-11T12:22:40.209876Z","shell.execute_reply.started":"2025-01-11T12:22:39.919305Z","shell.execute_reply":"2025-01-11T12:22:40.208527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The frequency of both sex, and the survival rate","metadata":{}},{"cell_type":"code","source":"df[\"Sex\"].value_counts(normalize=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:40.212099Z","iopub.execute_input":"2025-01-11T12:22:40.212433Z","iopub.status.idle":"2025-01-11T12:22:40.221113Z","shell.execute_reply.started":"2025-01-11T12:22:40.212401Z","shell.execute_reply":"2025-01-11T12:22:40.219932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.groupby(\"Sex\")[\"Survived\"].mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:40.222208Z","iopub.execute_input":"2025-01-11T12:22:40.222570Z","iopub.status.idle":"2025-01-11T12:22:40.249346Z","shell.execute_reply.started":"2025-01-11T12:22:40.222541Z","shell.execute_reply":"2025-01-11T12:22:40.247902Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Survival rate for people with how many siblings/spouses","metadata":{}},{"cell_type":"code","source":"df.groupby(\"SibSp\")[\"Survived\"].mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:40.250685Z","iopub.execute_input":"2025-01-11T12:22:40.251087Z","iopub.status.idle":"2025-01-11T12:22:40.272706Z","shell.execute_reply.started":"2025-01-11T12:22:40.251033Z","shell.execute_reply":"2025-01-11T12:22:40.271303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The survival rate of people with how many parents/children","metadata":{}},{"cell_type":"code","source":"df.groupby(\"Parch\")[\"Survived\"].mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:40.274070Z","iopub.execute_input":"2025-01-11T12:22:40.274508Z","iopub.status.idle":"2025-01-11T12:22:40.296322Z","shell.execute_reply.started":"2025-01-11T12:22:40.274465Z","shell.execute_reply":"2025-01-11T12:22:40.295259Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Distribution of fares","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.hist(df['Fare'], bins=50, edgecolor='black')\nplt.title('Distribution of Fare Prices')\nplt.xlabel('Fare')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:40.297491Z","iopub.execute_input":"2025-01-11T12:22:40.297957Z","iopub.status.idle":"2025-01-11T12:22:40.755712Z","shell.execute_reply.started":"2025-01-11T12:22:40.297922Z","shell.execute_reply":"2025-01-11T12:22:40.754520Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Distribution of fares and survival rates","metadata":{}},{"cell_type":"code","source":"fare_bins = pd.cut(df['Fare'], bins=range(0, int(df['Fare'].max())+50, 50))\nsurvival_by_fare = df.groupby(fare_bins, observed=True)['Survived'].mean()\nplt.figure(figsize=(12, 6))\nplt.bar(range(len(survival_by_fare)), survival_by_fare)\nplt.title('Survival Rate by Fare Price')\nplt.xlabel('Fare Range')\nplt.ylabel('Survival Rate')\nplt.xticks(range(len(survival_by_fare)), survival_by_fare.index.astype(str), rotation=45)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:40.756795Z","iopub.execute_input":"2025-01-11T12:22:40.757195Z","iopub.status.idle":"2025-01-11T12:22:41.044948Z","shell.execute_reply.started":"2025-01-11T12:22:40.757154Z","shell.execute_reply":"2025-01-11T12:22:41.043333Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Port of embarkation frequency and survival rate distribution","metadata":{}},{"cell_type":"code","source":"df[\"Embarked\"].value_counts(normalize=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.046113Z","iopub.execute_input":"2025-01-11T12:22:41.046452Z","iopub.status.idle":"2025-01-11T12:22:41.055994Z","shell.execute_reply.started":"2025-01-11T12:22:41.046420Z","shell.execute_reply":"2025-01-11T12:22:41.054930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.groupby(\"Embarked\")[\"Survived\"].mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.057373Z","iopub.execute_input":"2025-01-11T12:22:41.057713Z","iopub.status.idle":"2025-01-11T12:22:41.081183Z","shell.execute_reply.started":"2025-01-11T12:22:41.057680Z","shell.execute_reply":"2025-01-11T12:22:41.079961Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"According to our data visualization, the survival rate of women is significantly higher than that of men, the survival rate of first class is higher than that of first class than that of second class, the survival rate of children is higher than that of other ages, the survival rate of people with 1-2 siblings/spouses is significantly higher than that of others, the survival rate of people with 1-2 parents/children is significantly higher than that of others, and the survival rate of people with tickets above 500 is the highest. Those with fares below 50 have the lowest survival rates, and the port of embarkation in Cherbourg has a significantly higher survival rate than the others.","metadata":{}},{"cell_type":"markdown","source":"（2）baseline：logistic regression with basic features-accuracy 0.73","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\ntrain_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_data = pd.read_csv('/kaggle/input/titanic/test.csv')\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch']\nX = train_data[features].copy()\ny = train_data['Survived']\nX_test = test_data[features].copy()\nX['Age'] = X['Age'].fillna(X['Age'].median())\nX_test['Age'] = X_test['Age'].fillna(X_test['Age'].median())\nX_test['Fare'] = X_test['Fare'].fillna(X_test['Fare'].median())\nX['Sex'] = X['Sex'].map({'female': 1, 'male': 0})\nX_test['Sex'] = X_test['Sex'].map({'female': 1, 'male': 0})\nmodel = LogisticRegression(random_state=42)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\nsubmission = pd.DataFrame({\n    'PassengerId': test_data['PassengerId'],\n    'Survived': predictions\n})\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Feature Importance:\")\nfor feature, importance in zip(features, abs(model.coef_[0])):\n    print(f\"{feature}: {importance:.4f}\")\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\nval_model = LogisticRegression(random_state=42)\nval_model.fit(X_train, y_train)\nval_score = val_model.score(X_val, y_val)\nprint(f\"\\nAccuracy: {val_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.082727Z","iopub.execute_input":"2025-01-11T12:22:41.083223Z","iopub.status.idle":"2025-01-11T12:22:41.166052Z","shell.execute_reply.started":"2025-01-11T12:22:41.083165Z","shell.execute_reply":"2025-01-11T12:22:41.164906Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"baseline 2: RandomForest with basic features and feature engineering-accuracy 0.74","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\ntrain_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_data = pd.read_csv('/kaggle/input/titanic/test.csv')\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch']\nX = train_data[features].copy()\ny = train_data['Survived']\nX_test = test_data[features].copy()\nX['Age'] = X['Age'].fillna(X['Age'].median())\nX_test['Age'] = X_test['Age'].fillna(X_test['Age'].median())\nX_test['Fare'] = X_test['Fare'].fillna(X_test['Fare'].median())\nX['Sex'] = X['Sex'].map({'female': 1, 'male': 0})\nX_test['Sex'] = X_test['Sex'].map({'female': 1, 'male': 0})\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\nsubmission = pd.DataFrame({\n    'PassengerId': test_data['PassengerId'],\n    'Survived': predictions\n})\nsubmission.to_csv('submission.csv', index=False)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\nval_model = RandomForestClassifier(n_estimators=100, random_state=42)\nval_model.fit(X_train, y_train)\nval_score = val_model.score(X_val, y_val)\nprint(f\"\\nAccuracy: {val_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.167353Z","iopub.execute_input":"2025-01-11T12:22:41.167667Z","iopub.status.idle":"2025-01-11T12:22:41.632389Z","shell.execute_reply.started":"2025-01-11T12:22:41.167628Z","shell.execute_reply":"2025-01-11T12:22:41.631130Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# (2)：Within baseline, We started doing more detailed data preprocessing","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_data = pd.read_csv('/kaggle/input/titanic/test.csv')\ndf = train_data\ndf1 = test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.633479Z","iopub.execute_input":"2025-01-11T12:22:41.633835Z","iopub.status.idle":"2025-01-11T12:22:41.648419Z","shell.execute_reply.started":"2025-01-11T12:22:41.633795Z","shell.execute_reply":"2025-01-11T12:22:41.647050Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check the null values","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.649566Z","iopub.execute_input":"2025-01-11T12:22:41.650092Z","iopub.status.idle":"2025-01-11T12:22:41.663819Z","shell.execute_reply.started":"2025-01-11T12:22:41.650041Z","shell.execute_reply":"2025-01-11T12:22:41.662718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df1.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.665041Z","iopub.execute_input":"2025-01-11T12:22:41.665405Z","iopub.status.idle":"2025-01-11T12:22:41.687703Z","shell.execute_reply.started":"2025-01-11T12:22:41.665374Z","shell.execute_reply":"2025-01-11T12:22:41.686520Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now check the updated status of all features.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.688971Z","iopub.execute_input":"2025-01-11T12:22:41.689400Z","iopub.status.idle":"2025-01-11T12:22:41.719482Z","shell.execute_reply.started":"2025-01-11T12:22:41.689358Z","shell.execute_reply":"2025-01-11T12:22:41.718258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.720978Z","iopub.execute_input":"2025-01-11T12:22:41.721406Z","iopub.status.idle":"2025-01-11T12:22:41.763273Z","shell.execute_reply.started":"2025-01-11T12:22:41.721364Z","shell.execute_reply":"2025-01-11T12:22:41.761626Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# (3) Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"We try to handel Null values.\nfill null values with :\n\nmedian for numerical feaures\nmode for categorical features\nOr using linear regression","metadata":{}},{"cell_type":"markdown","source":"Next we try to extract all titles in the Name column and check the frequencies.","metadata":{}},{"cell_type":"code","source":"# Extract title from the Name column\ntrain_titles = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_titles = df1['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\nall_titles = pd.concat([train_titles, test_titles]).unique()\n# Sort the titles and convert them to a list\ntitles_list = sorted(list(all_titles))\nprint(\"Titles：\")\nprint(titles_list)\n# Check the frequency of title\n\nprint(\"\\nThe frequency of titles in train.csv：\")\nprint(train_titles.value_counts())\nprint(\"\\nThe frequency of title in test.csv：\")\nprint(test_titles.value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.764401Z","iopub.execute_input":"2025-01-11T12:22:41.764716Z","iopub.status.idle":"2025-01-11T12:22:41.779259Z","shell.execute_reply.started":"2025-01-11T12:22:41.764687Z","shell.execute_reply":"2025-01-11T12:22:41.777750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n# First we perform the basic feature transformation\nfor df2 in [df, df1]:\n    # Gender coding and basic characteristics processing\n    df2['Sex'] = df2['Sex'].map({'female': 0, 'male': 1})\n    df2['Fare'] = df2['Fare'].fillna(df2['Fare'].median())\n    df2['Embarked'] = df2['Embarked'].fillna(df2['Embarked'].mode()[0])\n    df2['Embarked'] = df2['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n    # Title extraction and mapping\n    df2['Title'] = df2['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    title_map = {\n        'Mr': 1, 'Don': 1,                    # Civilian males\n        'Miss': 2, 'Mlle': 2,                 # Unmarried women\n        'Mrs': 3, 'Ms': 3, 'Mme': 3,         # Married women\n        'Master': 4,                          # Young\n        'Countess': 5, 'Lady': 5, 'Dona': 5, # Noble wommen\n        'Jonkheer': 6, 'Sir': 6,             # Noble males\n        'Dr': 7,                             # Doctors\n        'Rev': 8,                            # Priests\n        'Col': 9, 'Major': 9, 'Capt': 9      # Specials\n    }\n    df2['Title'] = df2['Title'].map(title_map)\n\n# Age prediction for the training set and the test set were processed separately by linear regression.\nage_features_train = ['Pclass', 'Sex', 'Fare', 'Title', 'Survived', 'SibSp', 'Parch']\nknown_age_train = df[df['Age'].notna()]\nunknown_age_train = df[df['Age'].isna()]\nlr_model_train = LinearRegression(positive=True)\nlr_model_train.fit(known_age_train[age_features_train], known_age_train['Age'])\npredicted_ages_train = lr_model_train.predict(unknown_age_train[age_features_train])\ndf.loc[df['Age'].isna(), 'Age'] = predicted_ages_train\n\nage_features_test = ['Pclass', 'Sex', 'Fare', 'Title', 'SibSp', 'Parch']\nknown_age_train = df[df['Age'].notna()] \nlr_model_test = LinearRegression(positive=True)\nlr_model_test.fit(known_age_train[age_features_test], known_age_train['Age'])\nunknown_age_test = df1[df1['Age'].isna()]\npredicted_ages_test = lr_model_test.predict(unknown_age_test[age_features_test])\ndf1.loc[df1['Age'].isna(), 'Age'] = predicted_ages_test\n\nfor df2 in [df, df1]:\n    # Deck mapping\n    df2['Deck'] = df2['Cabin'].fillna('U').str[0]\n    deck_map = {\n        'A': 1, 'B': 2, 'C': 3, 'D': 4,\n        'E': 5, 'F': 6, 'G': 7, 'T': 8, 'U': 0\n    }\n    df2['Deck'] = df2['Deck'].map(deck_map)    \n    # Using fares to predict Deck\n    known_deck = df2[df2['Deck'] != 0]\n    lr_deck = LinearRegression()\n    lr_deck.fit(known_deck[['Fare', 'Title']], known_deck['Deck'])\n    unknown_deck = df2[df2['Deck'] == 0]\n    predicted_deck = lr_deck.predict(unknown_deck[['Fare', 'Title']])\n    df2.loc[df2['Deck'] == 0, 'Deck'] = np.round(predicted_deck)\n    \n    # Create composite features\n    df2['FamilySize'] = df2['SibSp'] + df2['Parch'] + 1\n    df2['Agebin'] = pd.qcut(df2['Age'], q=5, labels=False)\n    df2['Farebin'] = pd.qcut(df2['Fare'], q=5, labels=False)\n    df2['IsAlone'] = (df2['FamilySize'] == 1).astype(int)\n    df2['PclassSex'] = df2['Pclass'].astype(str) + df2['Sex'].astype(str)\n    df2['Fare/FamilySize'] = df2['Fare']/df2['FamilySize']\n    df2['Age_Class'] = df2['Age'] * df2['Pclass']\n    df2['FreeFare'] = df2['Fare'] == 0\n    # PclassSex mapping\n    pclass_sex_map = {\n        '10': 1, '11': 2,  \n        '20': 3, '21': 4, \n        '30': 5, '31': 6  \n    }\n    df2['PclassSex'] = df2['PclassSex'].map(pclass_sex_map)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.780380Z","iopub.execute_input":"2025-01-11T12:22:41.780723Z","iopub.status.idle":"2025-01-11T12:22:41.866231Z","shell.execute_reply.started":"2025-01-11T12:22:41.780692Z","shell.execute_reply":"2025-01-11T12:22:41.864900Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# (4): Model prediction and evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import classification_report\n# Choose the features\nfeatures = ['PclassSex', 'Agebin', 'Farebin', 'Embarked', 'FamilySize', 'Deck', 'Title', 'Fare/FamilySize', 'IsAlone', 'FreeFare']\n\n# Since Agebin and Farebin are categorical variables, unique thermal encoding is required\nX = pd.get_dummies(df[features])\ny = df['Survived']\nX_test = pd.get_dummies(df1[features], columns=['Agebin', 'Farebin'])\nX_test = X_test.reindex(columns=X.columns, fill_value=0)\n\n# Split train data and test data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=500, random_state=42, min_samples_leaf=5, min_samples_split=5, max_depth=3, max_features='log2')\nrf_model.fit(X_train, y_train)\nrf_score = rf_model.score(X_val, y_val)\nprint(f\"Random Forest Score: {rf_score:.4f}\")\n\n# Cross validation\nscores = cross_val_score(rf_model, X, y, cv=5)\nprint(f\"\\nRandom Forest Cross Validation Scores:\")\nprint(f\"Mean: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n\n# Prediction\nrf_predictions = rf_model.predict(X_test) \nrf_submission = pd.DataFrame({\n    'PassengerId': df1['PassengerId'],\n    'Survived': rf_predictions\n})\nrf_submission.to_csv('rf_titanic.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:41.870885Z","iopub.execute_input":"2025-01-11T12:22:41.871234Z","iopub.status.idle":"2025-01-11T12:22:47.162663Z","shell.execute_reply.started":"2025-01-11T12:22:41.871202Z","shell.execute_reply":"2025-01-11T12:22:47.160984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Output detailed categorical reports\ny_val_pred = rf_model.predict(X_val)\nprint(\"\\nReport:\")\nprint(classification_report(y_val, y_val_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:47.164293Z","iopub.execute_input":"2025-01-11T12:22:47.164785Z","iopub.status.idle":"2025-01-11T12:22:47.222664Z","shell.execute_reply.started":"2025-01-11T12:22:47.164721Z","shell.execute_reply":"2025-01-11T12:22:47.221510Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## We found that the recall rate of \"1\" is low(70%) compared to \"0\"(90%). Thus, we try to do sampling with SMOTETomek and clean up the sample to remove some of the most likely classes of noise","metadata":{}},{"cell_type":"code","source":"from imblearn.combine import SMOTETomek\n# Using SMOTETomek\nsmote = SMOTETomek(sampling_strategy=0.6, random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# View the category distribution after resampling\nprint(\"\\nCategory distribution after resampling:\")\nprint(pd.Series(y_train_resampled).value_counts())\n\n# Random Forest\nrf_model = RandomForestClassifier(\n    n_estimators=500, \n    random_state=42, \n    min_samples_leaf=5, \n    min_samples_split=5, \n    max_depth=3, \n    max_features='log2'\n)\nrf_model.fit(X_train_resampled, y_train_resampled)\n\nrf_score = rf_model.score(X_val, y_val)\nprint(f\"\\nRandom Forest Score on Validation Set: {rf_score:.4f}\")\n\n# Output detailed categorical reports\ny_val_pred = rf_model.predict(X_val)\nprint(\"\\nCategorial Report:\")\nprint(classification_report(y_val, y_val_pred))\n\n# Cross validation\nscores = cross_val_score(rf_model, X, y, cv=5)\nprint(f\"\\nRandom Forest Cross Validation Scores:\")\nprint(f\"Mean: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n\n# Check the feature importance\nfeature_importance = pd.DataFrame({\n    'feature': X.columns,\n    'importance': rf_model.feature_importances_\n})\nprint(\"\\nFeature Importance:\")\nprint(feature_importance.sort_values('importance', ascending=False))\n\n# Final prediction\nrf_predictions = rf_model.predict(X_test)\nrf_submission = pd.DataFrame({\n    'PassengerId': df1['PassengerId'],\n    'Survived': rf_predictions\n})\nrf_submission.to_csv('rf_prediction_with_SMOTE.csv', index=False)\nrf_submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T12:22:47.224000Z","iopub.execute_input":"2025-01-11T12:22:47.224395Z","iopub.status.idle":"2025-01-11T12:22:52.533038Z","shell.execute_reply.started":"2025-01-11T12:22:47.224357Z","shell.execute_reply":"2025-01-11T12:22:52.531249Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Finally, the accuracy is 0.7990","metadata":{}}]}